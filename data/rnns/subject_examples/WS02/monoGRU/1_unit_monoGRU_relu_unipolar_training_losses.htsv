train_prediction	val_pred_losses	train_sparsity	train_energy	train_hebbian	sparsity_lambda	energy_lambda	hebbian_lambda	weight_seed	epoch
0.8718480616807938	0.8211123943328857	4.1540759188052334e-07	3.7706601729858846e-11	0.0	1e-05	0.01		1	1
0.8556481748819351	0.8029579520225525	3.8923106160382304e-07	0.0	0.0	1e-05	0.01		1	2
0.8309926986694336	0.7861579060554504	4.7095673494368384e-07	0.0	0.0	1e-05	0.01		1	3
0.8137723356485367	0.7708696722984314	5.405343017628184e-07	0.0	0.0	1e-05	0.01		1	4
0.7946630418300629	0.7570818662643433	5.856194036368834e-07	0.0	0.0	1e-05	0.01		1	5
0.77633336186409	0.7448976039886475	5.837928398477743e-07	0.0	0.0	1e-05	0.01		1	6
0.7672090232372284	0.7342907786369324	5.974706454026091e-07	0.0	0.0	1e-05	0.01		1	7
0.7529150247573853	0.725128173828125	6.168451136545627e-07	0.0	0.0	1e-05	0.01		1	8
0.7403000146150589	0.7173446416854858	6.23778930730623e-07	0.0	0.0	1e-05	0.01		1	9
0.7314855754375458	0.7109837532043457	6.298362222878495e-07	0.0	0.0	1e-05	0.01		1	10
0.7229767739772797	0.7058283090591431	6.191366992425174e-07	0.0	0.0	1e-05	0.01		1	11
0.7169326394796371	0.7018023729324341	6.056645247554115e-07	0.0	0.0	1e-05	0.01		1	12
0.7116205543279648	0.6987112760543823	6.108997894216373e-07	0.0	0.0	1e-05	0.01		1	13
0.706516683101654	0.6964215636253357	6.227030837635539e-07	0.0	0.0	1e-05	0.01		1	14
0.7023665606975555	0.6948465704917908	6.369011487095122e-07	0.0	0.0	1e-05	0.01		1	15
0.6998224705457687	0.6938290596008301	5.978945551987636e-07	0.0	0.0	1e-05	0.01		1	16
0.6973341852426529	0.6932541728019714	6.103698950710168e-07	0.0	0.0	1e-05	0.01		1	17
0.6957791298627853	0.6930146217346191	6.165082595543936e-07	0.0	0.0	1e-05	0.01		1	18
0.6944445371627808	0.6930124163627625	6.239178134137546e-07	0.0	0.0	1e-05	0.01		1	19
0.6935324370861053	0.6931729912757874	5.867743482212973e-07	0.0	0.0	1e-05	0.01		1	20
0.6928048729896545	0.6934307217597961	5.865473440280766e-07	0.0	0.0	1e-05	0.01		1	21
0.6924672275781631	0.6937391757965088	5.87734845680643e-07	0.0	0.0	1e-05	0.01		1	22
0.6919054388999939	0.6940640211105347	5.760287393741237e-07	0.0	0.0	1e-05	0.01		1	23
0.6920434534549713	0.6943960189819336	5.684511847903195e-07	0.0	0.0	1e-05	0.01		1	24
0.6914944797754288	0.6946981549263	5.751405751652783e-07	0.0	0.0	1e-05	0.01		1	25
0.6917270123958588	0.6949702501296997	5.631715112031088e-07	0.0	0.0	1e-05	0.01		1	26
0.6918903589248657	0.6951969265937805	5.63788489671424e-07	0.0	0.0	1e-05	0.01		1	27
0.691614180803299	0.6953670978546143	5.604317863117103e-07	0.0	0.0	1e-05	0.01		1	28
0.6911762654781342	0.6955004334449768	5.642104952130467e-07	0.0	0.0	1e-05	0.01		1	29
0.6915209144353867	0.6956343054771423	5.362317523349702e-07	0.0	0.0	1e-05	0.01		1	30
0.6909639239311218	0.6957204937934875	5.392780764168492e-07	0.0	0.0	1e-05	0.01		1	31
0.6916341036558151	0.6958174705505371	5.332212253961188e-07	0.0	0.0	1e-05	0.01		1	32
0.6912559121847153	0.6958837509155273	5.382007657317445e-07	0.0	0.0	1e-05	0.01		1	33
0.6917306780815125	0.6959547400474548	5.204912412182239e-07	0.0	0.0	1e-05	0.01		1	34
0.6915291100740433	0.6959604620933533	5.354661709588981e-07	0.0	0.0	1e-05	0.01		1	35
0.6912535727024078	0.6959779262542725	5.159305800361835e-07	0.0	0.0	1e-05	0.01		1	36
0.6914663165807724	0.6959884762763977	5.043453228381622e-07	0.0	0.0	1e-05	0.01		1	37
0.6918502151966095	0.6959995627403259	4.805640614335971e-07	0.0	0.0	1e-05	0.01		1	38
0.6908172070980072	0.6959337592124939	4.854027295664309e-07	0.0	0.0	1e-05	0.01		1	39
