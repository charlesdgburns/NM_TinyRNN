train_prediction	val_pred_losses	train_sparsity	train_energy	train_hebbian	sparsity_lambda	energy_lambda	hebbian_lambda	weight_seed	epoch
0.8263231317202251	0.8828802704811096	5.816739954885483e-07	0.0	0.0	1e-05	0		1	1
0.8294601043065388	0.862099826335907	1.3339874271878216e-06	0.0	0.0	1e-05	0		1	2
0.8030590415000916	0.839862048625946	3.3825013664075714e-06	0.0	0.0	1e-05	0		1	3
0.7775053183237711	0.8167008757591248	5.511929430213058e-06	0.0	0.0	1e-05	0		1	4
0.7605770230293275	0.7932376861572266	7.793614865173975e-06	0.0	0.0	1e-05	0		1	5
0.773326575756073	0.7700298428535461	1.017506747302832e-05	0.0	0.0	1e-05	0		1	6
0.735570232073466	0.7481082081794739	1.2734577164034516e-05	0.0	0.0	1e-05	0		1	7
0.7283656199773153	0.7289254069328308	1.5168665716676816e-05	0.0	0.0	1e-05	0		1	8
0.7067867517471313	0.7136040925979614	1.7348712693395406e-05	0.0	0.0	1e-05	0		1	9
0.6996304988861084	0.7028864622116089	1.9100133310227346e-05	0.0	0.0	1e-05	0		1	10
0.6994160016377767	0.6957921981811523	2.0453215256566182e-05	0.0	0.0	1e-05	0		1	11
0.6953791975975037	0.6913922429084778	2.1825499667708453e-05	0.0	0.0	1e-05	0		1	12
0.6952733397483826	0.6889852285385132	2.327436838337841e-05	0.0	0.0	1e-05	0		1	13
0.6945489645004272	0.687958836555481	2.4392901953736633e-05	0.0	0.0	1e-05	0		1	14
0.6966278751691183	0.6875538229942322	2.5172479581669904e-05	0.0	0.0	1e-05	0		1	15
0.7004844943682352	0.6875061392784119	2.6000584815240778e-05	0.0	0.0	1e-05	0		1	16
0.6940094033877054	0.687747597694397	2.6776386221172288e-05	0.0	0.0	1e-05	0		1	17
0.6945687333742778	0.6880946755409241	2.7305216766156562e-05	0.0	0.0	1e-05	0		1	18
0.6963481108347574	0.6886028051376343	2.7753415148860462e-05	0.0	0.0	1e-05	0		1	19
0.6931334137916565	0.6891435980796814	2.8056866843447402e-05	0.0	0.0	1e-05	0		1	20
0.6955025990804037	0.6896503567695618	2.8316325672979773e-05	0.0	0.0	1e-05	0		1	21
0.6940882802009583	0.6900515556335449	2.8449717016580202e-05	0.0	0.0	1e-05	0		1	22
0.6929016510645548	0.6903358101844788	2.859090030445562e-05	0.0	0.0	1e-05	0		1	23
0.6937879125277202	0.6903699040412903	2.9061958533323676e-05	0.0	0.0	1e-05	0		1	24
0.6913392146428426	0.6901766061782837	2.958811031324634e-05	0.0	0.0	1e-05	0		1	25
0.6908543904622395	0.6895543336868286	3.0235746332133807e-05	0.0	0.0	1e-05	0		1	26
0.6922553976376852	0.688850998878479	3.101786690725324e-05	0.0	0.0	1e-05	0		1	27
0.6924377878506979	0.6882914900779724	3.172145564652358e-05	0.0	0.0	1e-05	0		1	28
0.6933894952138265	0.6879324316978455	3.229713790157499e-05	0.0	0.0	1e-05	0		1	29
0.6894037127494812	0.6878896355628967	3.272748290328309e-05	0.0	0.0	1e-05	0		1	30
0.6912805438041687	0.6879395842552185	3.3214040740858763e-05	0.0	0.0	1e-05	0		1	31
0.6949166854222616	0.6883169412612915	3.382791207210782e-05	0.0	0.0	1e-05	0		1	32
0.6920160253842671	0.688775360584259	3.428778533513348e-05	0.0	0.0	1e-05	0		1	33
0.6917059818903605	0.6892109513282776	3.471054636368839e-05	0.0	0.0	1e-05	0		1	34
0.689499576886495	0.6893157362937927	3.520202881190926e-05	0.0	0.0	1e-05	0		1	35
0.6933028697967529	0.6890293955802917	3.574301930105624e-05	0.0	0.0	1e-05	0		1	36
