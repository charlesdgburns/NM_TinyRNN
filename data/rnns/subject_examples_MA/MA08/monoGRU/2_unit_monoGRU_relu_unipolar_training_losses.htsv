train_prediction	val_pred_losses	train_sparsity	train_energy	train_hebbian	sparsity_lambda	energy_lambda	hebbian_lambda	weight_seed	epoch
0.6951149388363486	0.6815890669822693	4.7167172537779395e-06	2.3955500721154078e-05	0.0	1e-05	0.01		3	1
0.6619454873235601	0.6435194412867229	1.767171593919078e-05	0.00022424042866700083	0.0	1e-05	0.01		3	2
0.6080244779586792	0.5848673582077026	3.2576801267599594e-05	0.0011284160473702574	0.0	1e-05	0.01		3	3
0.5699338269861118	0.5668721397717793	4.4289249145597425e-05	0.0028368362384897316	0.0	1e-05	0.01		3	4
0.5634894104380357	0.5640057722727457	4.908940689730163e-05	0.0028141539078205824	0.0	1e-05	0.01		3	5
0.5602978216974359	0.5575772325197856	5.23442058214354e-05	0.002359816853545214	0.0	1e-05	0.01		3	6
0.5552782730052346	0.5544961194197336	5.5819682816754244e-05	0.00231780940176625	0.0	1e-05	0.01		3	7
0.5520687887543125	0.5534752011299133	5.730115490702077e-05	0.002181829278063225	0.0	1e-05	0.01		3	8
0.5507892887843282	0.5515883962313334	5.977104113921278e-05	0.0023567993071322377	0.0	1e-05	0.01		3	9
0.5490967929363251	0.5531274576981863	5.969918722832134e-05	0.001987170599597065	0.0	1e-05	0.01		3	10
0.5486217690141578	0.5523927509784698	6.092243443402511e-05	0.002155510727071056	0.0	1e-05	0.01		3	11
0.5489878434883919	0.5532883505026499	6.121511633912298e-05	0.0019975080289632865	0.0	1e-05	0.01		3	12
0.548256787814592	0.5524135927359264	6.16422349642227e-05	0.0019585622878941266	0.0	1e-05	0.01		3	13
0.5469413133043992	0.5513336360454559	6.159440396770246e-05	0.00193782265322577	0.0	1e-05	0.01		3	14
0.5467362890118047	0.55141877134641	6.165124987570667e-05	0.0019296122788402595	0.0	1e-05	0.01		3	15
0.5461999052449276	0.5512087841828665	6.111746571198302e-05	0.0018572663630996092	0.0	1e-05	0.01		3	16
0.5460187149675269	0.5525514185428619	6.073849267283406e-05	0.0017969084070309214	0.0	1e-05	0.01		3	17
0.5453771995870691	0.5531843304634094	6.08026319624562e-05	0.0018859386787210641	0.0	1e-05	0.01		3	18
0.5450298315600344	0.5526382724444072	5.9988428754303114e-05	0.0017978260293602943	0.0	1e-05	0.01		3	19
0.5448202773144372	0.5528482894102732	5.972109303049939e-05	0.0017373965820297597	0.0	1e-05	0.01		3	20
0.5462820953444429	0.5533084173997243	5.978984910670032e-05	0.0017928265243474593	0.0	1e-05	0.01		3	21
0.5444540161835519	0.5520065327485403	5.9887509498941285e-05	0.0017330956731089636	0.0	1e-05	0.01		3	22
0.5451707149806777	0.5549851655960083	6.010752718123657e-05	0.0016974873877571605	0.0	1e-05	0.01		3	23
0.5440514777836047	0.5523706078529358	5.972154318250862e-05	0.0016168415436129038	0.0	1e-05	0.01		3	24
0.5448272102757504	0.5537368456522624	5.9498787442479574e-05	0.001585542132440759	0.0	1e-05	0.01		3	25
0.5440410657932885	0.5539757510026295	5.9585681523649804e-05	0.0017079183905336418	0.0	1e-05	0.01		3	26
0.5465340943712937	0.5528287390867869	5.919476959541882e-05	0.0015803971572926172	0.0	1e-05	0.01		3	27
0.5452502871814527	0.5554889341195424	5.927171074099054e-05	0.0015088423816977364	0.0	1e-05	0.01		3	28
0.5434516856544896	0.5524342060089111	5.9332231582007606e-05	0.0015881905810123207	0.0	1e-05	0.01		3	29
0.5445798290403265	0.5543857713540395	5.900792625892025e-05	0.001644125343055317	0.0	1e-05	0.01		3	30
0.5434004899702575	0.5542326271533966	5.872931854499161e-05	0.001588659324242096	0.0	1e-05	0.01		3	31
0.5453609071279827	0.5535472929477692	5.802870873594657e-05	0.0014592418630950546	0.0	1e-05	0.01		3	32
0.5444340533331822	0.5530414481957754	5.782915602474915e-05	0.0015014937686684885	0.0	1e-05	0.01		3	33
0.5433834508845682	0.5533670087655386	5.800810762785227e-05	0.0015925709035639697	0.0	1e-05	0.01		3	34
0.5451063952947918	0.5528456767400105	5.830308414021458e-05	0.0015465009001720893	0.0	1e-05	0.01		3	35
0.5455108771198676	0.5556438763936361	5.764554149017817e-05	0.0013737966686389164	0.0	1e-05	0.01		3	36
