train_prediction	val_pred_losses	train_sparsity	train_energy	train_hebbian	sparsity_lambda	energy_lambda	hebbian_lambda	weight_seed	epoch
0.8622028757544125	0.8404415249824524	4.820829182125073e-07	1.4633750094048156e-11	0.0	1e-05	0.01		1	1
0.7857164460069994	0.7725813090801239	6.066799321214442e-07	0.0	0.0	1e-05	0.01		1	2
0.7364616078488968	0.7294867038726807	6.152852366165675e-07	0.0	0.0	1e-05	0.01		1	3
0.7098674633923698	0.7047761082649231	6.225202335318661e-07	0.0	0.0	1e-05	0.01		1	4
0.6966663108152502	0.6931795179843903	6.149281462592838e-07	0.0	0.0	1e-05	0.01		1	5
0.6922616643064161	0.6879214346408844	5.950880108684942e-07	0.0	0.0	1e-05	0.01		1	6
0.6900463349678938	0.6860909759998322	5.893235498553942e-07	0.0	0.0	1e-05	0.01		1	7
0.6898451307240654	0.6849195063114166	5.745588195542736e-07	0.0	0.0	1e-05	0.01		1	8
0.6896615975043353	0.684991329908371	5.602082437155117e-07	0.0	0.0	1e-05	0.01		1	9
0.6895027931998757	0.6842748820781708	5.434056801919616e-07	0.0	0.0	1e-05	0.01		1	10
0.6900926267399509	0.6836771070957184	5.364556727727177e-07	0.0	0.0	1e-05	0.01		1	11
0.6892842264736397	0.6845169067382812	5.173107792068227e-07	0.0	0.0	1e-05	0.01		1	12
0.6897553766475004	0.6849882304668427	4.912132985335868e-07	0.0	0.0	1e-05	0.01		1	13
0.6899360768935259	0.684272974729538	4.809274033130564e-07	0.0	0.0	1e-05	0.01		1	14
0.6894998760784374	0.6844694316387177	4.6398355547192783e-07	0.0	0.0	1e-05	0.01		1	15
0.6896378327818476	0.6841083467006683	4.3761234865889815e-07	0.0	0.0	1e-05	0.01		1	16
0.6894251879523782	0.6846634745597839	4.215875234796626e-07	0.0	0.0	1e-05	0.01		1	17
0.6895234409500571	0.684419184923172	4.030876037658719e-07	0.0	0.0	1e-05	0.01		1	18
0.6898787617683413	0.6850157976150513	3.80115090044509e-07	0.0	0.0	1e-05	0.01		1	19
0.689855505438412	0.6839651465415955	3.494660247457325e-07	0.0	0.0	1e-05	0.01		1	20
0.6899665418793174	0.6846436858177185	3.361139938399847e-07	0.0	0.0	1e-05	0.01		1	21
0.689675979754504	0.6847133934497833	3.118935514040084e-07	0.0	0.0	1e-05	0.01		1	22
0.6899676077506123	0.6840644776821136	2.8234401838744816e-07	0.0	0.0	1e-05	0.01		1	23
0.689315890564638	0.684306800365448	2.609247393833999e-07	0.0	0.0	1e-05	0.01		1	24
0.6900840296464809	0.6852182149887085	2.366297083506866e-07	0.0	0.0	1e-05	0.01		1	25
0.6894330908270443	0.6841590106487274	2.0447728509091524e-07	0.0	0.0	1e-05	0.01		1	26
0.6895804720766404	0.6839528381824493	1.749938718376143e-07	0.0	0.0	1e-05	0.01		1	27
0.689575847457437	0.6842204630374908	1.5309779190802683e-07	0.0	0.0	1e-05	0.01		1	28
0.6895515007131239	0.6841327846050262	1.286575635570925e-07	0.0	0.0	1e-05	0.01		1	29
0.6896241727997275	0.6842037737369537	9.182690435489565e-08	0.0	0.0	1e-05	0.01		1	30
0.6894705085193409	0.6847167909145355	6.94254425451725e-08	0.0	0.0	1e-05	0.01		1	31
